{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAP5415 Course Project:\n",
    "\n",
    "\"\"\"\n",
    "2D Image to 3D Model\n",
    "\n",
    "\n",
    "    In this project we will attempt to construct a 3D model out of a single 2D image. Compared to a 3D model, a single 2D image will have less data due to less dimensions. Therefore in order to move from a 2D to 3D represnetation, the algorithm needs to have prior knowledge of an object.\n",
    "\n",
    "    This is where machine learning algorithms come into play. For this task an autoencoder  structure is going to be a pretty good method. Autoencoders are a very efficient method of learning a compressed representation of an image. It compresses the representation, but also decompresses it. So with this logic, a 2D image is like a compressed version of a 3D model. So in a sense, the Autoencoder decompresses a 2D image into a 3D model.\n",
    "\n",
    "    Unlike a 2D image which is mainly represented by pixels (Although they can also be represented by vectors), a 3D model can be represented in many more ways in digital format. Each method has its strengths and weaknesses so choosing the right method is important when designing the Machine Learning model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Formats for Representing a 3D Model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Rasterized form (Volumetric Pixel/Voxel):\n",
    "\n",
    "    Are like the pixels used in 2D images but extended to 3D. The locality of ach voxel defines the structure of the 3D object. The locality means that this type of representation can be passed through a convolutional neural network.\n",
    "\n",
    "    A voxel is like building a solid object with internals. Like if you build a 3D cube, you will also be modeling the inside of the cube that isn't visible... This is wasteful because you can't see it.\n",
    "\n",
    "    The disadvantage is that as the resolution of the model increases, the density of useful voxels decreases. Voxels also require alot of computing power compared to other methods of 3D representation.\n",
    "\n",
    "\n",
    "Polygonal Mesh:\n",
    "\n",
    "    Is a collection of vertices, edges, and faces that defines an objects surface in 3D. It can capture alot of details and is compact due to the fact that only the surface is modeled and not the inner volume. The downside is that it cannot be pushed through a CNN.\n",
    "\n",
    "\n",
    "Point Cloud:\n",
    "\n",
    "    A collection of points in 3D coordinate (x,y,z) that form a cloud that resembles the 3D object. The more points in the cloud, the more detail it gets. The same set of points in a different order still represents the 3D object. The advantage is that this representation is compact, however it cannot be pushed through a CNN\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Approach\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "In implementing a model, we will be combining the advantages of the Point Cloud representation's compactness but also be able to use CNNs that Voxels allow in order to create a model with knowledge of shapes.\n",
    "\n",
    "    1. In order to use Point Clouds, will create an autoencoder.This autoencoder will project a single image to MULTIPLE 2D projections of a point cloud. So it's like slices of a 3D model. The formula is defined as:\n",
    "\n",
    "        2d Pojection == 3D coordinates (x,y,z) + binary mask (m)\n",
    "\n",
    "    The input will be a single RGB image and thr output will be point cloud 2D projections at predetermined viewpoints.\n",
    "\n",
    "\n",
    "    2.  The next step after creating multiple point cloud projections is to fuse these projections into a 3D cloud of points. This is possible because the viewpoints of the predictions are fixed and known beforehand.\n",
    "\n",
    "\n",
    "    3. The last step is to take this point cloud, and render different 2D images from new viewpoints by rotating the point cloud coordinates.\n",
    "\n",
    "\n",
    "We need to make the fusion of the 2D point cloud projections and the rendering steps differentiable and to use geometric reasoning. Geometric reasoning means no learnable parameters which decreases model size. Differentiable means that we can backpropagate gradients through it. This means the loss from 2D projections can be used to teach the model to generate a 3D Point Cloud.\n",
    "\n",
    "\n",
    "This point cloud can then be used by an external 3D software like Meshlab or Blender to create a voxel model or polygonal mesh that can be used for 3D Art, Graphics or 3D Printing.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Sources\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "1. Point Cloud: https://medium.com/vitalify-asia/create-3d-model-from-a-single-2d-image-in-pytorch-917aca00bb07\n",
    "\n",
    "2. Original Paper: https://chenhsuanlin.bitbucket.io/3D-point-cloud-generation/\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
