{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDue Date: 1ONov2023\\nAuthor: Lam Nguyen\\n\\nSubject: Nearest Neighbor Classification [2.5 pts]\\n\\nOverview:\\n\\nImplement the Nearest Neighbor Classifier for digit classification. We will use the digit dataset available from the sklearn library. \\n\\nTasks:\\n\\n1. Import and process the dataset.\\n    a. There are around 1800 images \\n    b. 10 digit classes\\n    c. Each image is 8x8 single channel.\\n    d. Split the dataset into training and testing, keep 500 images for testing\\n        i. Choose randomly with 50 images per class\\n\\n2. Implement Neighbor Classification using pixels as features. Test the method for classification accuracy.\\n\\n3. Implement a k-nearest neighbor classifier using pixels as features.\\n    a. Test method for k=3,5, and 7 and compute classification accuracy.\\n\\n4. Create a short writeup about implementation with results:\\n    1. Accuracy scores for all the variations\\n    2. Compare the variations using accuracy scores.\\n    3. Comment of how the accuracy changes when you increase the value of k\\n\\nNote: You can use L2-Norm for distance between 2 samples.\\n        \\n\\nSources:\\n\\nTrain Test Split: https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAP 5415 Programming Assignment 03: Nearest Neighbor Classification\n",
    "\n",
    "\"\"\"\n",
    "Due Date: 1ONov2023\n",
    "Author: Lam Nguyen\n",
    "\n",
    "Subject: Nearest Neighbor Classification [2.5 pts]\n",
    "\n",
    "Overview:\n",
    "\n",
    "Implement the Nearest Neighbor Classifier for digit classification. We will use the digit dataset available from the sklearn library. \n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Import and process the dataset.\n",
    "    a. There are around 1800 images \n",
    "    b. 10 digit classes\n",
    "    c. Each image is 8x8 single channel.\n",
    "    d. Split the dataset into training and testing, keep 500 images for testing\n",
    "        i. Choose randomly with 50 images per class\n",
    "\n",
    "2. Implement Neighbor Classification using pixels as features. Test the method for classification accuracy.\n",
    "\n",
    "3. Implement a k-nearest neighbor classifier using pixels as features.\n",
    "    a. Test method for k=3,5, and 7 and compute classification accuracy.\n",
    "\n",
    "4. Create a short writeup about implementation with results:\n",
    "    1. Accuracy scores for all the variations\n",
    "    2. Compare the variations using accuracy scores.\n",
    "    3. Comment of how the accuracy changes when you increase the value of k\n",
    "\n",
    "Note: You can use L2-Norm for distance between 2 samples.\n",
    "        \n",
    "\n",
    "Sources:\n",
    "\n",
    "Train Test Split: https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================#\n",
    "# 1. Load Modules\n",
    "# ========================================================================================#\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of Test Labels: [6 9 3 7 2 1 5 2 5 2 1 9 4 0 4 2 3 7 8 8 4 3 9 7 5 6 3 5 6 3 4 9 1 4 4 6 9\n",
      " 4 7 6 6 9 1 3 6 1 3 0 6 5 5 1 9 5 6 0 9 0 0 1 0 4 5 2 4 5 7 0 7 5 9 5 5 4\n",
      " 7 0 4 5 5 9 9 0 2 3 8 0 6 4 4 9 1 2 8 3 5 2 9 0 4 4 4 3 5 3 1 3 5 9 4 2 7\n",
      " 7 4 4 1 9 2 7 8 7 2 6 9 4 0 7 2 7 5 8 7 5 7 7 0 6 6 4 2 8 0 9 4 6 9 9 6 9\n",
      " 0 3 5 6 6 0 6 4 3 9 3 9 7 2 9 0 4 5 3 6 5 9 9 8 4 2 1 3 7 7 2 2 3 9 8 0 3\n",
      " 2 2 5 6 9 9 4 1 5 4 2 3 6 4 8 5 9 5 7 8 9 4 8 1 5 4 4 9 6 1 8 6 0 4 5 2 7\n",
      " 4 6 4 5 6 0 3 2 3 6 7 1 5 1 4 7 6 8 8 5 5 1 6 2 8 8 9 9 7 6 2 2 2 3 4 8 8\n",
      " 3 6 0 9 7 7 0 1 0 4 5 1 5 3 6 0 4 1 0 0 3 6 5 9 7 3 5 5 9 9 8 5 3 3 2 0 5\n",
      " 8 3 4 0 2 4 6 4 3 4 5 0 5 2 1 3 1 4 1 1 7 0 1 5 2 1 2 8 7 0 6 4 8 8 5 1 8\n",
      " 4 5 8 7 9 8 5 0 6 2 0 7 9 8 9 5 2 7 7 1 8 7 4 3 8 3 5 6 0 0 3 0 5 0 0 4 1\n",
      " 2 8 4 5 9 6 3 1 8 8 4 2 3 8 9 8 8 5 0 6 3 3 7 1 6 4 1 2 1 1 6 4 7 4 8 3 4\n",
      " 0 5 1 9 4 5 7 6 3 7 0 5 9 7 5 9 7 4 2 1 9 0 7 5 3 3 6 3 9 6 9 5 0 1 5 5 8\n",
      " 3 3 6 2 6 5 5 2 0 8 7 3 7 0 2 2 3 5 8 7 3 6 5 9 9 2 5 6 3 0 7 1 1 9 6 1 1\n",
      " 0 0 2 9 3 9 9 3 7 7 1 3 5 4 6 1 2 1 1]\n",
      "Size of Test Data Set: 500\n",
      "Array of training features: [[ 0.  0. 13. ...  3.  0.  0.]\n",
      " [ 0.  0. 10. ...  0.  0.  0.]\n",
      " [ 0.  0.  6. ... 14.  2.  0.]\n",
      " ...\n",
      " [ 0.  0.  9. ... 16.  2.  0.]\n",
      " [ 0.  0.  1. ...  0.  0.  0.]\n",
      " [ 0.  0.  1. ...  1.  0.  0.]]\n",
      "Size of Training Data Set: 1297\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================================#\n",
    "# 2. Load and Process Data\n",
    "# ========================================================================================#\n",
    "\n",
    "\n",
    "digits = load_digits() # Create instance of dataset\n",
    "\n",
    "image_data = digits.data # Create instance of data arrays without labels\n",
    "image_targets = digits.target # Create instance of data labels\n",
    "\n",
    "\n",
    "# Split data into Training and test groups\n",
    "train_features,test_features, train_labels,test_labels = train_test_split(\n",
    "image_data, image_targets, test_size=500, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Array of Test Labels: {test_labels}') # Should show an array with all labels\n",
    "\n",
    "print(f'Size of Test Data Set: {len(test_labels)}') # Should give 500\n",
    "\n",
    "print(f'Length of Array of training features: {len(train_features)}') # Should show an array with all labels\n",
    "\n",
    "print(f'Size of Training Data Set: {len(train_labels)}') # Should give around 1300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
