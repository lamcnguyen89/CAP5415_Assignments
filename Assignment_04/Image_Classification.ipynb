{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAP 5415 Programming Assignment 04: Image Classification\n",
    "\n",
    "\"\"\"\n",
    "Design a CNN architecture which has more then 2 convolutional layers and more then 1 fully connected layers. It should make 10 predictions for the 10 classes of CIFAR-10.\n",
    "\n",
    "1. Train this network on CIFAR-10 for 30 epochs\n",
    "2. Use Cross-Entropy Loss\n",
    "3. SGD Optimizer\n",
    "4. Softmax activation after the final fully connected layer.\n",
    "5. Report Training/Testing Loss after each epoch in the form of plots and accuracy scores after 30 epochs.\n",
    "\n",
    "6. Finally, increase the number of conv layers in the above network and train again. Report the same numbers and plots again comparing with the first network.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================#\n",
    "# 1. Import basic Modules and Functions and set variables\n",
    "# =======================================================#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # All the Neural network models, loss functions\n",
    "import torch.optim as optim # Optimization algorithms\n",
    "import torch.nn.functional as F # All functions without parameters\n",
    "from torch.utils.data import DataLoader # Easier dataset management such as minibatches\n",
    "import torchvision.datasets as datasets # Standard datasets that can be used as test training data\n",
    "import torchvision.transforms as transforms # Transformations that can be performed on the dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "# Import some packages for logging training and showing progress\n",
    "from tqdm_loggable.auto import tqdm\n",
    "from tqdm_loggable.tqdm_logging import tqdm_logging\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "# Set up some basic logging to record traces of training\n",
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        filename=\"output/output.txt\" # Save log to a file\n",
    "    )\n",
    "\n",
    "tqdm_logging.set_level(logging.INFO)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_channels = 3\n",
    "hidden_size = 100\n",
    "num_classes= 10\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================#\n",
    "# 2. Next insert two Convolutional Laters to the network built in previous step:\n",
    "# ================================================================================#\n",
    "\n",
    "class NN_2(nn.Module):\n",
    "    def __init__(self,input_channels,hidden_size, num_classes):\n",
    "        super(NN_2, self).__init__() # The Super keyword calls the initialization of the parent class\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels,\n",
    "                               out_channels=40,\n",
    "                               kernel_size=(5,5),\n",
    "                               stride=(1,1),\n",
    "                               padding=(0,0)\n",
    "                               )\n",
    "        self.conv2 = nn.Conv2d(in_channels=40,\n",
    "                               out_channels=40,\n",
    "                               kernel_size=(5,5),\n",
    "                               stride=(1,1),\n",
    "                               padding=(0,0)\n",
    "                               )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2),\n",
    "                                  stride=(2,2)\n",
    "        ) \n",
    "        self.fc1 = nn.Linear(40*5*5, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:] # all dimensions except batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *=s\n",
    "\n",
    "        return num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.sigmoid(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.softmax(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================#\n",
    "# 3. Load and prepare dataset:\n",
    "# =======================================================#\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='dataset/', \n",
    "               train=True, \n",
    "               transform=transforms.ToTensor(),\n",
    "               download=True\n",
    "               )#Transforms transforms numpy array to tensors so that pytorch can use the data\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='dataset/', \n",
    "               train=False, \n",
    "               transform=transforms.ToTensor(),\n",
    "               download=True\n",
    "               )#Transforms transforms numpy array to tensors so that pytorch can use the data\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset= test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================#\n",
    "# 4. Define Accuracy Function:\n",
    "# =======================================================#\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "        logging.info(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "        logging.info(\"Checking accuracy on test data\")\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(): # No gradients have to be calculated\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _,predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}')\n",
    "        logging.info(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}')\n",
    "\n",
    "    model.train()\n",
    "    acc = num_correct/num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Step 1/2 Training Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/tmp/ipykernel_7265/1549013987.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc1(x))\n",
      "100%|██████████| 5000/5000 [00:07<00:00, 712.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2749128341674805\n",
      "Step 1/2 Training Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 712.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3191261291503906\n",
      "Step 1/2 Training Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 709.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2953810691833496\n",
      "Step 1/2 Training Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 698.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3359806537628174\n",
      "Step 1/2 Training Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 716.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.311763286590576\n",
      "Step 1/2 Training Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 710.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.089271068572998\n",
      "Step 1/2 Training Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 722.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.958928108215332\n",
      "Step 1/2 Training Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 710.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8494170904159546\n",
      "Step 1/2 Training Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 714.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0298585891723633\n",
      "Step 1/2 Training Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 198/5000 [00:00<00:06, 708.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m tqdm\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStep 1/2 Training Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# store points for for plotting the accuracy and loss:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m batch_idx, (data, targets) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(tqdm(train_loader)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# Get data to Cuda/gpu if possible\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     data \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/malneyugnfl/softwaredev/CAP5415_Assignments/Assignment_04/Image_Classification.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     targets \u001b[39m=\u001b[39;49m targets \u001b[39m=\u001b[39;49m targets\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/softwaredev/anaconda3/envs/deeplearning/lib/python3.11/site-packages/PIL/Image.py:3089\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3087\u001b[0m \u001b[39mif\u001b[39;00m strides \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3088\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mtobytes\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 3089\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m   3090\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =======================================================#\n",
    "# 5. Train the Convolutional Neural Network:\n",
    "# =======================================================#\n",
    "\n",
    "model_accuracy = []\n",
    "model_loss = []\n",
    "\n",
    "#Initialize Model\n",
    "model = NN_2(\n",
    "    input_channels=input_channels,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "logging.info(f\"Begin Training CIFAR-10 dataset with this model: {model}\")\n",
    "\n",
    "# Define the loss function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=learning_rate)\n",
    "\n",
    "epoch_counter= 0\n",
    "current_loss = 1\n",
    "current_accuracy = 1\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0:\n",
    "        print(f'Current Loss: {current_loss:.4f}')\n",
    "        print(f'Current Accuracy: {current_accuracy:.4f}')\n",
    "    tqdm.write(f\"Step 1/2 Training Epoch {epoch+1}/{num_epochs}\")\n",
    "    # store points for for plotting the accuracy and loss:\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        \n",
    "        # Get data to Cuda/gpu if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets = targets.to(device=device)\n",
    "    \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Go Backward in the network:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        current_accuracy = check_accuracy(train_loader,model)\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        # logging.info(\"Training single layer Neural Network \")\n",
    "        if epoch > epoch_counter+4:\n",
    "            logging.info(f\"Training Epoch: {epoch}, loss = {loss.item():.4f}\")\n",
    "\n",
    "            epoch_counter = epoch\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch_counter = 0\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(),'trained_models/Classifier_01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================#\n",
    "# 6. Check Accuracy on training and test to see the accuracy of the model:\n",
    "# =========================================================================#\n",
    "\n",
    "\n",
    "check_accuracy(train_loader,model)\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================================================#\n",
    "# 7. Graph Training/Testing Loss after each epoch in the form of plots and accuracy scores after 30 epochs:\n",
    "# =========================================================================================================#\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
