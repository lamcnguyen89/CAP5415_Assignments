{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDesign a CNN architecture which has more then 2 convolutional layers and more then 1 fully connected layers. It should make 10 predictions for the 10 classes of CIFAR-10.\\n\\n1. Train this network on CIFAR-10 for 30 epochs\\n2. Use Cross-Entropy Loss\\n3. SGD Optimizer\\n4. Softmax activation after the final fully connected layer.\\n5. Report Training/Testing Loss after each epoch in the form of plots and accuracy scores after 30 epochs.\\n\\n6. Finally, increase the number of conv layers in the above network and train again. Report the same numbers and plots again comparing with the first network.\\n\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAP 5415 Programming Assignment 04: Image Classification\n",
    "\n",
    "\"\"\"\n",
    "Design a CNN architecture which has more then 2 convolutional layers and more then 1 fully connected layers. It should make 10 predictions for the 10 classes of CIFAR-10.\n",
    "\n",
    "1. Train this network on CIFAR-10 for 30 epochs\n",
    "2. Use Cross-Entropy Loss\n",
    "3. SGD Optimizer\n",
    "4. Softmax activation after the final fully connected layer.\n",
    "5. Report Training/Testing Loss after each epoch in the form of plots and accuracy scores after 30 epochs.\n",
    "\n",
    "6. Finally, increase the number of conv layers in the above network and train again. Report the same numbers and plots again comparing with the first network.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================#\n",
    "# 1. Import basic Modules and Functions and set variables\n",
    "# =======================================================#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # All the Neural network models, loss functions\n",
    "import torch.optim as optim # Optimization algorithms\n",
    "import torch.nn.functional as F # All functions without parameters\n",
    "from torch.utils.data import DataLoader # Easier dataset management such as minibatches\n",
    "import torchvision.datasets as datasets # Standard datasets that can be used as test training data\n",
    "import torchvision.transforms as transforms # Transformations that can be performed on the dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "# Import some packages for logging training and showing progress\n",
    "from tqdm_loggable.auto import tqdm\n",
    "from tqdm_loggable.tqdm_logging import tqdm_logging\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "# Set up some basic logging to record traces of training\n",
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        filename=\"output/output.txt\" # Save log to a file\n",
    "    )\n",
    "\n",
    "tqdm_logging.set_level(logging.INFO)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_channels = 3\n",
    "hidden_size = 100\n",
    "num_classes= 10\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================#\n",
    "# 2. Next insert two Convolutional Laters to the network built in previous step:\n",
    "# ================================================================================#\n",
    "\n",
    "class NN_2(nn.Module):\n",
    "    def __init__(self,input_channels,hidden_size, num_classes):\n",
    "        super(NN_2, self).__init__() # The Super keyword calls the initialization of the parent class\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels,\n",
    "                               out_channels=40,\n",
    "                               kernel_size=(5,5),\n",
    "                               stride=(1,1),\n",
    "                               padding=(0,0)\n",
    "                               )\n",
    "        self.conv2 = nn.Conv2d(in_channels=40,\n",
    "                               out_channels=40,\n",
    "                               kernel_size=(5,5),\n",
    "                               stride=(1,1),\n",
    "                               padding=(0,0)\n",
    "                               )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2),\n",
    "                                  stride=(2,2)\n",
    "        ) \n",
    "        self.fc1 = nn.Linear(40*5*5, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:] # all dimensions except batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *=s\n",
    "\n",
    "        return num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.sigmoid(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.softmax(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# =======================================================#\n",
    "# 3. Load and prepare dataset:\n",
    "# =======================================================#\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='dataset/', \n",
    "               train=True, \n",
    "               transform=transforms.ToTensor(),\n",
    "               download=True\n",
    "               )#Transforms transforms numpy array to tensors so that pytorch can use the data\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='dataset/', \n",
    "               train=False, \n",
    "               transform=transforms.ToTensor(),\n",
    "               download=True\n",
    "               )#Transforms transforms numpy array to tensors so that pytorch can use the data\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset= test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================#\n",
    "# 4. Define Accuracy Function:\n",
    "# =======================================================#\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "        logging.info(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "        logging.info(\"Checking accuracy on test data\")\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(): # No gradients have to be calculated\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _,predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}')\n",
    "        logging.info(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}')\n",
    "\n",
    "    model.train()\n",
    "    acc = float(num_correct)/float(num_samples)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/2 Training Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/tmp/ipykernel_13182/1549013987.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc1(x))\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 293.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 5000 / 50000 with accuracy 10.00\n",
      "Step 1/2 Training Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:17<00:00, 293.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: [0.1]\n",
      "Model Loss: [2.297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================#\n",
    "# 5. Train the Convolutional Neural Network:\n",
    "# =======================================================#\n",
    "\n",
    "\n",
    "\n",
    "#Initialize Model\n",
    "model = NN_2(\n",
    "    input_channels=input_channels,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "logging.info(f\"Begin Training CIFAR-10 dataset with this model: {model}\")\n",
    "\n",
    "# Define the loss function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=learning_rate)\n",
    "\n",
    "# Set Some state variables\n",
    "epoch_counter= 0\n",
    "current_loss = 1\n",
    "current_accuracy = 1\n",
    "model_accuracy = []\n",
    "model_loss = []\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0:\n",
    "        current_accuracy = check_accuracy(train_loader,model)\n",
    "        model_accuracy.append(current_accuracy)\n",
    "        model_loss.append(round(current_loss, 4))\n",
    "    tqdm.write(f\"Step 1/2 Training Epoch {epoch+1}/{num_epochs}\")\n",
    "    # store points for for plotting the accuracy and loss:\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        \n",
    "        # Get data to Cuda/gpu if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets = targets.to(device=device)\n",
    "    \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Go Backward in the network:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        # logging.info(\"Training single layer Neural Network \")\n",
    "        if epoch > epoch_counter+4:\n",
    "            logging.info(f\"Training Epoch: {epoch}, loss = {loss.item():.4f}\")\n",
    "\n",
    "            epoch_counter = epoch\n",
    "\n",
    "\n",
    "epoch_counter = 0\n",
    "\n",
    "print(f'Model Accuracy: {model_accuracy}')\n",
    "print(f'Model Loss: {model_loss}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(),'trained_models/Classifier_01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================================================#\n",
    "# 7. Graph Training/Testing Loss after each epoch in the form of plots and accuracy scores after 30 epochs:\n",
    "# =========================================================================================================#\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
